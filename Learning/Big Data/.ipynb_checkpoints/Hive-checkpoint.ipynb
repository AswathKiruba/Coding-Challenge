{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hive is not a database. \n",
    "* It just poinst to data lying in HDFS.\n",
    "* Hive is not suitable for OLTP.\n",
    "* Does not provide row level Insert, Update and delete. \n",
    "* Not used where fast response time is required as in RDBMS.\n",
    "\n",
    "Hive is built on write once and read many concept.\n",
    "\n",
    "***ARCHITECTURE***\n",
    "Driver: converts the SQL to MapReduce program.\n",
    "Compiler: symentatic analysis of the code and aids in coverting SQL to MapReduce.\n",
    "MetaStore: Stores info on the table\n",
    "Execution engine: Connected with hadoop system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table creation\n",
    "\n",
    "* By default Hive creates internal Tables (where the data and metadata is governed by Hive). When dropped both data and metadata is deleted.\n",
    "* For external tables Hive only governs the metadata\n",
    "\n",
    "\n",
    "```\n",
    "CREATE TABLE IF NOT EXISTS table_1 (\n",
    "    col1 string,\n",
    "    col2 array<string>,\n",
    "    col3 string,\n",
    "    col4 int\n",
    ")\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n",
    "COLLECTION ITEMS TERMINATED BY ':'\n",
    "LINES TERMINATED BY '\\n'\n",
    "STORED AS TEXTFILE; \n",
    "```\n",
    "- default file format is TEXTFILE FORMAT\n",
    "- default DELIMITED FIELDS TERMINATED BY ' '\n",
    "\n",
    "-- default location\n",
    "set hive.metastore.warehouse.dir (user/hive/warehouse)\n",
    "\n",
    "Change locations while creating table using,\n",
    "`\n",
    "LOCATION 'user/aswath/table_1'\n",
    "`\n",
    "\n",
    "**SORTING IN HIVE**\n",
    "1. ORDER BY -- needs to be passed through a single reducer\n",
    "2. SORT BY -- Sort by orders the data in each reducer (uses two reducers)\n",
    "3. DISTRIBUTED BY -- Hive uses key value pairs to distributed the data among reducer. It does not perform any sorting. Hence you should follow it by SORT command.\n",
    "4. CLUSTER BY-- combination of Distribute by + Sort by\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning\n",
    "\n",
    "Partitioning is a way of dividing a table into related parts based on the values of particular columns. Reduces the scan time.\n",
    "\n",
    "### Static partitioning\n",
    "\n",
    "Add the line in create table statement `PARTITONED BY (departmentname STRING)`\n",
    "\n",
    "Insert Statment \n",
    "\n",
    "`INSERT INTO TABLE department PARTITION (deptname='XYZ')`\n",
    "\n",
    "**Advantages:** fast\n",
    "\n",
    "Partitions are created when data is inserted into table. Depending on how you load data you would need partitions. Usually when loading files (big files) into Hive tables static partitions are preferred. That saves your time in loading data compared to dynamic partition. You \"statically\" add a partition in table and move the file into the partition of the table. Since the files are big they are usually generated in HDFS. You can get the partition column value form the filename, day of date etc without reading the whole big file.\n",
    "\n",
    "\n",
    "### Dynamic partitioning\n",
    "\n",
    "Allowing the table create the partitions dynamically based on the values inserted to the column which the user defined as a partition column.\n",
    "\n",
    "Same create statement. But `set hive.exec.dynamic.partition=true`\n",
    "and `set hive.exec.dynamic.partition.mode = nonstrict` (disables the restriction on creating a table with atleast one static partition)\n",
    "\n",
    "`INSERT INTO TABLE  department PARTITION (deptname)`\n",
    "\n",
    "**Advantage** slow\n",
    "\n",
    "Incase of dynamic partition whole big file i.e. every row of the data is read and data is partitioned through a MR job into the destination tables depending on certain field in file. So usually dynamic partition are useful when you are doing sort of a ETL flow in your data pipeline. e.g. you load a huge file through a move command into a Table X. then you run a inert query into a Table Y and partition data based on field in table X say day , country. You may want to further run a ETL step to partition the data in country partition in Table Y into a Table Z where data is partitioned based on cities for a particular country only. etc.\n",
    "\n",
    "Thus depending on your end table or requirements for data and in what form data is produced at source you may choose static or dynamic partition.\n",
    "\n",
    "### When to use Partitioning?\n",
    "\n",
    "- When the column with a high search query has low cardinality. For example, if you create a partition by the country name then a maximum of 195 partitions will be made and these number of directories are manageable by the hive.\n",
    "- On the other hand, do not create partitions on the columns with very high cardinality. For example- product IDs, timestamp, and price because will create millions of directories which will be impossible for the hive to manage.\n",
    "- It is effective when the data volume in each partition is not very high. For example, if you have the airline data and you want to calculate the total number of flights in a day. In that case, the result will take more time to calculate over the partition “Dubai” as it has one of the busiest airports in the world whereas for the country like “Albania” will return results quicker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucketing\n",
    "\n",
    "* Another data organizing technique in Hive. Decomposing large dataset into a more manageable one.\n",
    "* All the same column values of a bucketed column will go into same bucket.\n",
    "* A partition is a directory and bucket is a actually file with your data.\n",
    "* The data to a particular bucket is decided by an hashing function.\n",
    "* Bucketing can sometimes be more efficient when used alone.\n",
    "* Bucketed map joins are the fastest joins. (Condition: Both joining tables should be bucketed on same column as of joining column and both tables should have equal number of buckets.)\n",
    "\n",
    "\n",
    "`set hive.enforce.bucketing = true;`\n",
    "\n",
    "ADD THIS TO THE CREATE STATEMENT\n",
    "\n",
    "`CLUSTERED BY (location) into 4 buckets`\n",
    "\n",
    "### WHY bucketting?\n",
    "\n",
    "- We cannot do partitioning on a column with very high cardinality. Too many partitions will result in multiple Hadoop files which will increase the load on the same node as it has to carry the metadata of each of the partitions.\n",
    "- If some map-side joins are involved in your queries, then bucketed tables are a good option. Map side join is a process where two tables are joins using the map function only without any reduced function. I would recommed you to go through this article for more understanding about map-side joins: Map Side Joins in Hive\n",
    "\n",
    "### Table sampling\n",
    "\n",
    "Table sampling helps to collect distributed data from different buckets and partition.\n",
    "\n",
    "```\n",
    "SELECT\n",
    "    deptno,\n",
    "    empname,\n",
    "    sal,\n",
    "    location\n",
    "FROM dept_table\n",
    "TABLESAMPLE (bucket 2 out of 3 on location)\n",
    "```\n",
    "\n",
    "**no_drop** \n",
    "\n",
    "`ALTER TABLE emp_tab enable no_drop;`\n",
    "\n",
    "`ALTER TABLE emp_tab enable PARTITION(dept='HR') no_drop;`\n",
    "\n",
    "**offline**\n",
    "\n",
    "no one can query it.\n",
    "\n",
    "`ALTER TABLE emp_tab enable offline;`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JOINS\n",
    "\n",
    "In the last table in query is streamed and the rest are buffered in memory.\n",
    "\n",
    "### MAP JOINS\n",
    "\n",
    "The reducer wont be used here. The mapper will be used to join tables. Use smaller tables in map joins.\n",
    "\n",
    "FULL OUTER MAP JOINS CANNOT BE PERFORMED\n",
    "\n",
    "### Bucketed map joins\n",
    "\n",
    "Set the properties.\n",
    "**Condition:** Both joining tables should be bucketed on same column as of joining column and both tables should have equal number of buckets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Views\n",
    "\n",
    "Virtual table created as a result of a Hive query on a table.\n",
    "\n",
    "- Views do not contain any data of its own.\n",
    "- All type of DML operation can be performed on Views.\n",
    "- Can be created by selecting any number of rows or columns of its base table/taables.\n",
    "- Once created, the schema of view is frozen and is independent of chnages made to base table schema.\n",
    "- Vice-versa of above is also True.\n",
    "- View are read-only\n",
    "- Drop the table and we can not fire queries on its view.\n",
    "\n",
    "**Advantages**\n",
    "- Views can be used to hide underlying table columns from some users.\n",
    "- Views protect our base table from being accidently dropped or altered.\n",
    "- Views can help turning the lengthy and complicated query into a one-liner query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "An Index act as reference to records. Used to speed up searching the data.\n",
    "- Will search for only the portion of data and not whole data set.\n",
    "- Partition done at HDFS level and indexing is done at table level.\n",
    "\n",
    "`CREATE INDEX I1 ON TABLE dept(name) AS 'COMPACT' WITH DEFERRED REBUILD;`\n",
    "\n",
    "COMPACT:\n",
    "\n",
    "BIT MAP: \n",
    "\n",
    "**When to use**\n",
    "- Dataset is large (GB or more)\n",
    "- speed is an concern\n",
    "- Frequent use of where clause in queries\n",
    "\n",
    "**When not to use**\n",
    "- Dataset is unique\n",
    "- No frequent use of where clause in queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties\n",
    "\n",
    "while creating a table we could add table properties\n",
    "\n",
    "Add following to create statement\n",
    "\n",
    "* `TBLPROPERTIES(\"skip.header.line.count\"=\"3\")`\n",
    "* `TBLPROPERTIES(\"skip.footer.line.count\"=\"3\")`\n",
    "* `TBLPROPERTIES(\"immutable\"=\"true\")` (Insert overwrite wont be affected)\n",
    "\n",
    "DROP TABLE [IF EXISTS] table_name [PURGE];\n",
    "\n",
    "If you don't use purge the table goes to a Trash directory, from there the table can be recovered after drop it. But if you do use purge table won't go to Trash directory, so it can't be recovered.\n",
    "\n",
    "Setting empty values as NULL Value\n",
    "\n",
    "`TBLPROPERTIES(\"serialization.null.format\"=\"\")`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACID (Transactional features of Hive)\n",
    "\n",
    "* Only supports ORC File format\n",
    "* Table must be bucketed\n",
    "* Begin, commit, rollback features are also not supported.\n",
    "* Reading/Writing to a ACID table is only allowed in a session where transactional properties are true.\n",
    "\n",
    "For even a single row update a spark job is initiated in Hive. Hence a Hive is good database for transactionaly system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEZ\n",
    "\n",
    "set hive.execution.enginer = tez\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
